This project read/scraps biographies on wikipedia, and collect the articles for text processing.
A base text is preloaded on tarea1/tarea1/base.csv

Scrapy crawler:

$ cd tarea1/
$ scrapy crawl wiki -o base.csv

The text processing, is done in Jupyter notebook